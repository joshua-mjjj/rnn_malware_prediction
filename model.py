# Author: Joshua Mwesigwa, shredakajoshua@gmail.com

import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix, roc_curve, auc
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM, Dropout, GRU, Bidirectional
from keras import optimizers
from itertools import cycle
import itertools
from utils import read_data, extract_segments
from utils import plot_confusion_matrix, plotroc


if __name__ == '__main__':

    """Hyperparameters"""
    win_size =19 
    num_var = 10
    split_ratio = 0.8

    print("Loading Data from file......")
    print("=============================")

    train_data = read_data("train.csv")
    
    print("Data loaded from file......")
    print("=============================")

    # Data preprocessing
    print("Preprocessing and standardizing data for model input......")
    print("=============================")

    segments, labels = extract_segments(train_data, win_size)
    segments = segments.astype(float)

    labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)
    reshaped_segments = segments.reshape(
        [int(len(segments) / (win_size)), (win_size), num_var])

    # # """Create Train and Test Split based on split ratio"""

    train_test_split = np.random.rand(len(reshaped_segments)) < split_ratio
    print(len(train_test_split))
    train_x = reshaped_segments[train_test_split]
    train_y = labels[train_test_split]

    test_x = reshaped_segments[~train_test_split]
    test_y = labels[~train_test_split]

    def standardize(train, test):
        mean = np.mean(train, axis=0)
        std = np.std(train, axis=0)+0.000001

        train_x = (train - mean) / std 
        test_x = (test - mean) / std 
        return train_x, test_x

    train_x, test_x = standardize(train_x, test_x)

    print("Preprocessing Done......")
    print("=============================")

    print("Buiding model......")
    print("=============================")
    # input_shape=(timesteps, in_size)

    # create and fit the LSTM network
    model = Sequential()
    model.add(LSTM(units=128, input_dim=num_var, input_length=win_size, return_sequences=True, dropout=0.2))
    model.add(LSTM(128, return_sequences=True, dropout=0.2))
    model.add(LSTM(64, return_sequences=True, dropout=0.3))
    model.add(LSTM(64, return_sequences=False, dropout=0.3))
    # model.add(Dropout(0.2))
    model.add(Dense(2, activation='sigmoid'))
    opt = optimizers.Adam(learning_rate=0.0001)
    model.compile(optimizer=opt, loss='binary_crossentropy',
                  metrics=['accuracy'])
    model.summary()
    
    print("Buiding Done......")
    print("=============================")
    print("Training model......")
    print("=============================")

    # Fit the network
    history = model.fit(train_x, 
                        train_y, 
                        epochs=40, 
                        batch_size=64,
                        verbose=1, 
                        # validation_split=0.1
                        validation_data=(test_x, test_y),
                    )

    print("Training DONE!!......")
    print("=============================")

    print("Saving weights!!......")
    print("=============================")

    # serialize model to JSON
    model_json = model.to_json()
    with open("lstm_model_1.json", "w") as json_file:
        json_file.write(model_json)
    # serialize weights to HDF5
    model.save_weights("lstm_model_1.h5")
    print("Saved model to disk.....")
 

    print("Representing Results......")
    print("=============================")

    # Plotting loss track 
    plt.plot(history.history['loss'], label='Training loss')
    plt.plot(history.history['val_loss'], label='Validation loss')
    plt.title('Model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend()
    plt.savefig("model_loss" + ".png")

    print(history.history.keys())
    # summarize history for accuracy
    plt.figure() 
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend()
    plt.savefig("model_accuracy" + ".png")


    # Predict Test Data and Plot ROC
    pred_y = model.predict(test_x, batch_size=64, verbose=2)
    plotroc(test_y, pred_y, 2, 'Testing ROC')
    class_names = ['Class 0, Benign', 'Class 1, Malware']
    plot_confusion_matrix(test_y, pred_y, class_names, 'test_confusion_matrix')

    pred_y = model.predict(train_x, batch_size=64, verbose=2)
    plotroc(train_y, pred_y, 2, 'Training ROC')
    plot_confusion_matrix(train_y, pred_y, class_names, 'train_confusion_matrix')

    

   
