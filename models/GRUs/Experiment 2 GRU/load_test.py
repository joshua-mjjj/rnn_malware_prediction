from tensorflow.keras.models import Sequential, model_from_json
from tensorflow.keras.layers import Dense
import numpy
import os
import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix, roc_curve, auc
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from keras import optimizers
from itertools import cycle
import itertools
from sklearn.metrics import classification_report
from utils import read_data, extract_segments


# load json and create model
json_file = open('gru_model_2.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("gru_model_2.h5")
print("Loaded model from disk...")



win_size =19 
num_var = 10
split_ratio = 0.8

print("Loading Data from file......")
print("=============================")

train_data = read_data("train.csv")

print("Data loaded from file......")
print("=============================")

# Data preprocessing
print("Preprocessing and standardizing data for model input......")
print("=============================")

segments, labels = extract_segments(train_data, win_size)
segments = segments.astype(float)

labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)
reshaped_segments = segments.reshape(
    [int(len(segments) / (win_size)), (win_size), num_var])

# # """Create Train and Test Split based on split ratio"""

train_test_split = np.random.rand(len(reshaped_segments)) < split_ratio

train_x = reshaped_segments[train_test_split]
train_y = labels[train_test_split]

test_x = reshaped_segments[~train_test_split]
test_y = labels[~train_test_split]

def standardize(train, test):
    mean = np.mean(train, axis=0)
    std = np.std(train, axis=0)+0.000001

    train_x = (train - mean) / std 
    test_x = (test - mean) / std 
    return train_x, test_x

train_x, test_x = standardize(train_x, test_x)
 


print("Classfication Report for Malware Prediction GRU model 2")
# evaluate loaded model on test data
opt = optimizers.Adam(learning_rate=0.0001)
loaded_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])

class_names = ['Class 0, Benign', 'Class 1, Malware']
pred_y = loaded_model.predict(test_x, batch_size=64, verbose=2)
y_pred_bool = np.argmax(pred_y, axis=1)
test_y = np.argmax(test_y, axis=1)

print(classification_report(test_y, y_pred_bool, target_names=class_names))

tn, fp, fn, tp = confusion_matrix(test_y, np.argmax(pred_y, axis=1)).ravel()
tot = tn+tp+fp+fn

print('* False Positive Rate: ', fp/tot)
print('* False Negative Rate: ', fn/tot)

print('True Positive Rate: ', tp/tot)
print('True Negative Rate: ', tn/tot)
